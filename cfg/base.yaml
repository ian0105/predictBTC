seed_everything: 4444
data:
  class_path: lightning.UpbitDataModule
  init_args:
    train_params:
      filelist_path: ../BTC.csv
      batch_size: 16
      num_workers: 4
      data_period: 1440
      train_ratio: 0.95
      target_data: close
      data_term: 300
    val_params:
      filelist_path: ../BTC.csv
      batch_size: 4
      num_workers: 2
      data_period: 1440
      train_ratio: 0.95
      target_data: close
      data_term: 300
model:
  class_path: lightning.CoinPredict
  init_args:
    initial_learning_rate: 0.001
    num_warmup_steps: 0
    model_config:
      input_dim: 1
      hidden_size: 256


trainer:
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: logs/
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: vocos_checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 3
        save_last: true
    - class_path: utils.helpers.GradNormCallback

  # Lightning calculates max_steps across all optimizer steps (rather than number of batches)
  # This equals to 1M steps per generator and 1M per discriminator
  max_steps: 2000000
  # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  limit_val_batches: 30
  accelerator: gpu
  strategy: ddp
  devices: 1
  log_every_n_steps: 100
  check_val_every_n_epoch: 1


